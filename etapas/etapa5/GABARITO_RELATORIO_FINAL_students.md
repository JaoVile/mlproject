# Relat√≥rio Final - Projeto de Machine Learning
## Predi√ß√£o de Desempenho Acad√™mico de Estudantes
 
**Dataset:** students_performance.csv  
**Disciplina:** Introdu√ß√£o √† Machine Learning - 2025.2

---

## üìã Sum√°rio Executivo

Este projeto teve como objetivo desenvolver um modelo preditivo capaz de estimar o desempenho acad√™mico final de estudantes universit√°rios utilizando t√©cnicas de Machine Learning. O dataset utilizado cont√©m informa√ß√µes de 2.495 estudantes com 23 features (ap√≥s feature engineering) relacionadas a h√°bitos de estudo, condi√ß√µes socioecon√¥micas, fatores de sa√∫de e engajamento acad√™mico.

Ap√≥s um processo rigoroso de an√°lise explorat√≥ria, pr√©-processamento, modelagem e otimiza√ß√£o, foi desenvolvido um modelo Random Forest otimizado capaz de prever notas finais com **MAE de 3.45 pontos** e **R¬≤ de 0.89** no conjunto de teste. O modelo demonstrou capacidade de generaliza√ß√£o consistente e pode ser utilizado para identificar estudantes em risco de baixo desempenho, permitindo interven√ß√µes preventivas.

**Principais Resultados:**
- **Modelo Final:** Random Forest com hiperpar√¢metros otimizados
- **Performance:** MAE = 3.45, RMSE = 4.67, R¬≤ = 0.89
- **Melhoria:** 12.3% de redu√ß√£o no MAE comparado ao baseline
- **Features Importantes:** previous_scores (28%), study_hours (19%), attendance_rate (15%)

---

## üéØ 1. Introdu√ß√£o

### 1.1 Contextualiza√ß√£o do Problema

No contexto educacional moderno, universidades e institui√ß√µes de ensino enfrentam o desafio constante de identificar precocemente estudantes em risco de baixo desempenho acad√™mico. A detec√ß√£o antecipada desses casos permite a implementa√ß√£o de estrat√©gias de interven√ß√£o, como programas de tutoria personalizada, aconselhamento acad√™mico e suporte adicional, resultando em melhores taxas de sucesso e redu√ß√£o da evas√£o escolar.

Tradicionalmente, a identifica√ß√£o de estudantes em risco ocorre apenas ap√≥s avalia√ß√µes parciais ou quando j√° h√° sinais evidentes de dificuldade. Com t√©cnicas de Machine Learning, √© poss√≠vel analisar m√∫ltiplos fatores simultaneamente e realizar predi√ß√µes mais precisas e antecipadas, considerando caracter√≠sticas demogr√°ficas, h√°bitos de estudo, condi√ß√µes socioecon√¥micas e indicadores de engajamento.

### 1.2 Objetivos

**Objetivo Geral:**
Desenvolver um modelo de Machine Learning capaz de prever com precis√£o a nota final de estudantes universit√°rios com base em caracter√≠sticas observ√°veis no in√≠cio do per√≠odo letivo.

**Objetivos Espec√≠ficos:**
1. Realizar an√°lise explorat√≥ria completa para identificar padr√µes e rela√ß√µes nos dados
2. Implementar pipeline de pr√©-processamento robusto com tratamento de dados ausentes e outliers
3. Comparar diferentes algoritmos de regress√£o (Linear Regression, Ridge, Lasso, Random Forest)
4. Otimizar hiperpar√¢metros do melhor modelo usando Grid Search com valida√ß√£o cruzada
5. Avaliar o modelo final no conjunto de teste e analisar erros de predi√ß√£o
6. Identificar as features mais importantes para o desempenho acad√™mico
7. Alcan√ßar RMSE inferior a 6.0 pontos na escala de 0-100

### 1.3 Dataset

**Caracter√≠sticas Principais:**

| Atributo | Descri√ß√£o |
|----------|-----------|
| **Nome** | Students Performance Dataset |
| **Fonte** | Dataset educacional sint√©tico baseado em padr√µes reais |
| **Tamanho Original** | 2.495 estudantes √ó 13 features |
| **Tamanho Processado** | 2.495 estudantes √ó 23 features (ap√≥s feature engineering) |
| **Vari√°vel Alvo** | `final_grade` - Nota final do estudante (escala 0-100) |
| **Tipo de Problema** | Regress√£o |
| **Missing Values** | Sim - 5.2% dos dados (tratados na Etapa 2) |
| **Outliers** | Sim - Identificados e tratados seletivamente |

**Features Originais:**
- **Demogr√°ficas:** age, gender, parental_education, family_income
- **Acad√™micas:** previous_scores, attendance_rate
- **H√°bitos:** study_hours_per_week, sleep_hours_per_night, extracurricular_activities
- **Suporte:** tutoring_sessions, internet_quality
- **Sa√∫de:** health_status, access_to_resources

---

## üìä 2. An√°lise Explorat√≥ria de Dados (EDA)

### 2.1 Vis√£o Geral dos Dados

**Estat√≠sticas do Dataset Original:**

| M√©trica | Valor |
|---------|-------|
| Total de Registros | 2.495 |
| Total de Features | 13 (originais) |
| Features Num√©ricas | 5 |
| Features Categ√≥ricas | 8 |
| Valores Faltantes | 129 (5.2%) |
| Registros Duplicados | 0 |
| Faixa da Vari√°vel Alvo | 45.23 - 100.00 |

**Distribui√ß√£o de Missing Values:**

| Feature | Missing Count | Missing % |
|---------|--------------|-----------|
| study_hours_per_week | 48 | 1.92% |
| sleep_hours_per_night | 45 | 1.80% |
| tutoring_sessions | 36 | 1.44% |
| **Total** | **129** | **5.17%** |

### 2.2 An√°lise da Vari√°vel Alvo

**Estat√≠sticas de `final_grade`:**

```
M√©trica          | Valor
-----------------|--------
M√©dia            | 82.47
Mediana          | 84.12
Desvio Padr√£o    | 11.85
M√≠nimo           | 45.23
Q1 (25%)         | 74.56
Q3 (75%)         | 91.38
M√°ximo           | 100.00
Assimetria       | -0.42 (leve assimetria √† esquerda)
Curtose          | -0.15 (distribui√ß√£o aproximadamente normal)
```

**Interpreta√ß√£o:**
- Distribui√ß√£o aproximadamente normal com leve concentra√ß√£o em notas mais altas
- M√©dia de 82.47 indica que a maioria dos estudantes tem bom desempenho
- Desvio padr√£o de 11.85 pontos mostra variabilidade moderada
- Aus√™ncia de valores extremos fora do intervalo esperado (0-100)

### 2.3 An√°lise de Correla√ß√µes

**Top 10 Features Mais Correlacionadas com final_grade:**

| Feature | Correla√ß√£o | Interpreta√ß√£o |
|---------|-----------|---------------|
| previous_scores | 0.78 | Forte - Desempenho passado √© forte preditor |
| attendance_rate | 0.62 | Moderada/Forte - Presen√ßa impacta positivamente |
| study_hours_per_week | 0.58 | Moderada - Mais horas de estudo = melhores notas |
| tutoring_sessions | 0.45 | Moderada - Suporte adicional ajuda |
| sleep_hours_per_night | 0.38 | Fraca/Moderada - Sono adequado √© importante |
| health_status | 0.34 | Fraca/Moderada - Sa√∫de afeta desempenho |
| internet_quality | 0.28 | Fraca - Acesso a recursos digitais importa |
| parental_education | 0.25 | Fraca - Background familiar tem influ√™ncia |
| access_to_resources | 0.22 | Fraca - Recursos materiais ajudam |
| extracurricular_activities | -0.08 | Muito Fraca - Correla√ß√£o negativa leve |

**Descobertas Importantes:**
1. **previous_scores** √© o preditor mais forte (r=0.78) - hist√≥rico acad√™mico √© crucial
2. Fatores comportamentais (attendance, study_hours) t√™m correla√ß√µes moderadas
3. Fatores socioecon√¥micos t√™m correla√ß√µes fracas, mas presentes
4. Atividades extracurriculares t√™m correla√ß√£o negativa leve (pode indicar sobrecarga)

### 2.4 An√°lise por Grupos Categ√≥ricos

**Desempenho M√©dio por G√™nero:**
```
G√™nero     | M√©dia  | Desvio Padr√£o | Contagem
-----------|--------|---------------|----------
Female     | 83.2   | 11.4          | 1.247
Male       | 81.7   | 12.2          | 1.184
Non-binary | 82.5   | 11.9          | 64
```

**Desempenho por N√≠vel Educacional dos Pais:**
```
Educa√ß√£o Parental | M√©dia  | Contagem
------------------|--------|----------
High School       | 78.3   | 623
Bachelor          | 82.1   | 987
Master            | 85.4   | 542
Doctorate         | 87.2   | 343
```
**Observa√ß√£o:** Correla√ß√£o positiva entre educa√ß√£o dos pais e desempenho dos filhos.

**Desempenho por Faixa de Renda Familiar:**
```
Renda      | M√©dia  | Mediana | Contagem
-----------|--------|---------|----------
Low        | 79.1   | 80.5    | 798
Medium     | 83.5   | 85.1    | 1.124
High       | 86.8   | 88.4    | 573
```

### 2.5 An√°lise de Outliers

**Outliers Identificados (m√©todo IQR):**

| Feature | Outliers Detectados | % do Dataset | A√ß√£o Tomada |
|---------|-------------------|--------------|-------------|
| study_hours_per_week | 34 | 1.36% | Mantidos (valores v√°lidos) |
| sleep_hours_per_night | 28 | 1.12% | Mantidos (valores v√°lidos) |
| previous_scores | 12 | 0.48% | Investigados individualmente |
| final_grade | 8 | 0.32% | Mantidos (notas leg√≠timas) |

**Decis√£o:** Outliers foram mantidos por representarem casos extremos mas v√°lidos (ex: estudantes excepcionais ou com dificuldades severas).

### 2.6 Principais Insights da EDA

‚úÖ **Achados Relevantes:**

1. **Preditor Principal:** Notas anteriores (previous_scores) s√£o o melhor preditor individual
2. **Import√¢ncia da Frequ√™ncia:** Attendance rate tem forte correla√ß√£o - presen√ßa √© crucial
3. **Horas de Estudo:** Correla√ß√£o moderada positiva - quantidade de estudo importa
4. **Fatores Socioecon√¥micos:** Impacto moderado - renda e educa√ß√£o parental influenciam
5. **Sa√∫de e Sono:** Correla√ß√µes fracas mas presentes - bem-estar afeta aprendizado
6. **Qualidade de Dados:** 94.8% dos dados completos - boa qualidade geral
7. **Distribui√ß√£o Balanceada:** Sem desbalanceamento severo entre categorias

---

## üîß 3. Pr√©-processamento e Feature Engineering

### 3.1 Tratamento de Valores Faltantes

**Estrat√©gia Aplicada:**

| Feature | Tipo | Missing % | Estrat√©gia | Justificativa |
|---------|------|-----------|------------|---------------|
| study_hours_per_week | Num√©rica | 1.92% | Mediana | Robusta a outliers, preserva distribui√ß√£o |
| sleep_hours_per_night | Num√©rica | 1.80% | Mediana | Menos sens√≠vel a valores extremos |
| tutoring_sessions | Num√©rica | 1.44% | Zero | Missing = sem tutoria (MNAR) |

**Abordagem MNAR (Missing Not At Random):**
Para `tutoring_sessions`, valores ausentes foram interpretados como "nenhuma sess√£o de tutoria", sendo preenchidos com 0. Esta decis√£o foi baseada na hip√≥tese de que estudantes que n√£o preencheram este campo provavelmente n√£o participaram de tutoria.

**Resultados:**
- ‚úÖ 100% dos dados completos ap√≥s tratamento
- ‚úÖ Distribui√ß√µes originais preservadas
- ‚úÖ Nenhum vi√©s introduzido pela imputa√ß√£o

### 3.2 Feature Engineering

**Novas Features Criadas:**

#### 3.2.1 Transforma√ß√µes Matem√°ticas

```python
# Transforma√ß√£o Logar√≠tmica (reduzir skewness)
study_hours_week_log = log(study_hours_per_week + 1)

# Transforma√ß√£o de Raiz Quadrada (estabilizar vari√¢ncia)
sleep_hours_sqrt = sqrt(sleep_hours_per_night)
```

**Justificativa:** Transforma√ß√µes n√£o-lineares capturam rela√ß√µes n√£o-lineares e melhoram normalidade.

#### 3.2.2 Features de Intera√ß√£o

```python
# Raz√£o entre horas de estudo e sono
study_sleep_ratio = study_hours_per_week / sleep_hours_per_night

# Indicador de engajamento geral
engagement = (attendance_rate * study_hours_per_week) / 100
```

**Justificativa:** Capturar sinergias entre vari√°veis que interagem.

#### 3.2.3 Normaliza√ß√£o/Padroniza√ß√£o

**T√©cnica:** StandardScaler (z-score normalization)

```python
# F√≥rmula: z = (x - Œº) / œÉ
z_score = (value - mean) / std_dev
```

**Features Padronizadas:**
- age, previous_scores, attendance_rate
- study_hours_week_log, sleep_hours_sqrt
- study_sleep_ratio, engagement

**Resultado:** Todas as features num√©ricas com m√©dia ‚âà 0 e desvio padr√£o = 1

#### 3.2.4 Encoding de Vari√°veis Categ√≥ricas

**One-Hot Encoding aplicado em:**
- gender (3 categorias ‚Üí 3 features bin√°rias)
- parental_education (4 categorias ‚Üí 4 features)
- family_income (3 categorias ‚Üí 3 features)
- extracurricular_activities (Yes/No ‚Üí 1 feature)
- tutoring (Yes/No ‚Üí 1 feature)
- internet_quality (Good/Poor ‚Üí 2 features)
- health_status (Good/Poor ‚Üí 2 features)

**Total de Features Ap√≥s Encoding:** 13 originais ‚Üí 23 finais

### 3.3 Divis√£o dos Dados

**Estrat√©gia de Split:**

```
Dataset Completo (2.495 estudantes)
    ‚Üì
    ‚îú‚îÄ Treino (60%):     1.497 estudantes  ‚Üê Treinar modelos
    ‚îú‚îÄ Valida√ß√£o (20%):    499 estudantes  ‚Üê Tuning e sele√ß√£o
    ‚îî‚îÄ Teste (20%):        499 estudantes  ‚Üê Avalia√ß√£o final
```

**Justificativas:**
- **60% Treino:** Volume suficiente para aprendizado
- **20% Valida√ß√£o:** Adequado para compara√ß√£o de modelos e tuning
- **20% Teste:** Hold-out final para avalia√ß√£o n√£o enviesada
- **random_state=42:** Reprodutibilidade dos resultados

**Verifica√ß√£o de Distribui√ß√£o:**
- ‚úÖ Distribui√ß√£o de final_grade similar nos 3 conjuntos
- ‚úÖ Propor√ß√µes de categorias preservadas
- ‚úÖ Sem data leakage entre conjuntos

---

## ü§ñ 4. Modelagem e Compara√ß√£o

### 4.1 Modelos Testados

Foram implementados e comparados 4 modelos de regress√£o:

#### Modelo 1: Regress√£o Linear
```python
LinearRegression()
```
**Caracter√≠sticas:**
- Modelo baseline mais simples
- Assume rela√ß√£o linear entre features e target
- Sem hiperpar√¢metros para tuning
- Alta interpretabilidade

#### Modelo 2: Ridge Regression (Regulariza√ß√£o L2)
```python
Ridge(alpha=1.0)
```
**Caracter√≠sticas:**
- Adiciona penaliza√ß√£o L2: Œª‚àë(Œ≤¬≤)
- Reduz overfitting em datasets com multicolinearidade
- Mant√©m todas as features (coeficientes pequenos, n√£o zero)

#### Modelo 3: Lasso Regression (Regulariza√ß√£o L1)
```python
Lasso(alpha=0.1)
```
**Caracter√≠sticas:**
- Adiciona penaliza√ß√£o L1: Œª‚àë|Œ≤|
- Feature selection autom√°tica (alguns coeficientes = 0)
- √ötil quando h√° muitas features irrelevantes

#### Modelo 4: Random Forest Regressor
```python
RandomForestRegressor(n_estimators=100, random_state=42)
```
**Caracter√≠sticas:**
- Ensemble de √°rvores de decis√£o
- Captura rela√ß√µes n√£o-lineares
- Robusto a outliers
- Feature importance nativa

### 4.2 Resultados no Conjunto de Valida√ß√£o

**Compara√ß√£o de Performance:**

| Modelo | MAE ‚Üì | RMSE ‚Üì | R¬≤ ‚Üë | Tempo Treino |
|--------|-------|--------|------|--------------|
| **Random Forest** | **3.54** | **4.78** | **0.88** | 2.3s |
| Ridge | 4.12 | 5.45 | 0.84 | 0.02s |
| Lasso | 4.23 | 5.52 | 0.83 | 0.05s |
| Linear Regression | 4.18 | 5.48 | 0.84 | 0.01s |

**An√°lise dos Resultados:**

‚úÖ **Random Forest: MELHOR PERFORMANCE**
- MAE mais baixo (3.54 pontos)
- Melhor R¬≤ (0.88 - explica 88% da vari√¢ncia)
- Captura rela√ß√µes n√£o-lineares efetivamente

‚ö†Ô∏è **Modelos Lineares: Performance Similar**
- Ridge e Linear Regression praticamente empatados
- Lasso ligeiramente pior (pode ter removido features √∫teis)
- Extremamente r√°pidos (< 0.05s)

üí° **Trade-off:**
- Random Forest: Melhor acur√°cia √ó Maior complexidade
- Modelos Lineares: Menor acur√°cia √ó Maior interpretabilidade

### 4.3 Sele√ß√£o do Modelo Final

**Decis√£o:** Random Forest foi selecionado como modelo base para otimiza√ß√£o.

**Justificativa:**
1. ‚úÖ Melhor performance em todas as m√©tricas
2. ‚úÖ Melhoria significativa de 14% no MAE vs modelos lineares
3. ‚úÖ Captura intera√ß√µes complexas entre features
4. ‚úÖ Fornece feature importance (interpretabilidade parcial)
5. ‚úÖ Robusto a outliers e dados ruidosos
6. ‚ö†Ô∏è Trade-off aceit√°vel: complexidade √ó ganho de performance

---

## ‚öôÔ∏è 5. Otimiza√ß√£o de Hiperpar√¢metros

### 5.1 Processo de Tuning

**T√©cnica:** Grid Search com 5-Fold Cross-Validation

**Estrat√©gia:**
```python
GridSearchCV(
    estimator=RandomForestRegressor(random_state=42),
    param_grid={...},
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1
)
```

**Hiperpar√¢metros Testados:**

| Hiperpar√¢metro | Valores Testados | Total |
|----------------|------------------|-------|
| n_estimators | [100, 200, 300] | 3 |
| max_depth | [10, 15, 20, None] | 4 |
| min_samples_split | [2, 5, 10] | 3 |
| min_samples_leaf | [1, 2, 4] | 3 |

**Total de Combina√ß√µes:** 3 √ó 4 √ó 3 √ó 3 = **108 configura√ß√µes**  
**Total de Modelos Treinados:** 108 √ó 5 (CV) = **540 modelos**  
**Tempo Total:** ~8 minutos em CPU de 8 cores

### 5.2 Melhores Hiperpar√¢metros Encontrados

**Configura√ß√£o √ìtima:**

```python
{
    'n_estimators': 300,        # Mais √°rvores = maior estabilidade
    'max_depth': 20,            # Profundidade controlada evita overfitting
    'min_samples_split': 2,     # Permite divis√µes mais espec√≠ficas
    'min_samples_leaf': 1       # Folhas podem ter 1 amostra
}
```

**Interpreta√ß√£o:**

- **n_estimators=300:** N√∫mero alto de √°rvores melhora estabilidade sem overfitting significativo
- **max_depth=20:** Profundidade moderada balanceia complexidade e generaliza√ß√£o
- **min_samples_split=2:** Permite capturar padr√µes espec√≠ficos sem for√ßar generaliza√ß√£o excessiva
- **min_samples_leaf=1:** Maior flexibilidade nas folhas (Random Forest √© resistente a overfitting)

### 5.3 Compara√ß√£o: Baseline vs Otimizado

**Resultados no Conjunto de Valida√ß√£o (Cross-Validation):**

| Modelo | MAE | Melhoria |
|--------|-----|----------|
| Random Forest Baseline (default) | 3.54 | - |
| Random Forest Otimizado (Grid Search) | 3.21 | **-9.3%** ‚Üì |

**An√°lise:**
- ‚úÖ Otimiza√ß√£o reduziu MAE em 0.33 pontos (9.3% de melhoria)
- ‚úÖ Melhoria consistente atrav√©s dos 5 folds de CV
- ‚úÖ Desvio padr√£o reduzido (modelo mais est√°vel)

### 5.4 Top 5 Configura√ß√µes Encontradas

| Rank | n_estimators | max_depth | min_samples_split | min_samples_leaf | MAE (CV) |
|------|-------------|-----------|-------------------|------------------|----------|
| 1 | 300 | 20 | 2 | 1 | 3.21 |
| 2 | 300 | None | 2 | 1 | 3.23 |
| 3 | 200 | 20 | 2 | 1 | 3.25 |
| 4 | 300 | 15 | 2 | 1 | 3.27 |
| 5 | 200 | None | 2 | 1 | 3.28 |

**Observa√ß√£o:** As 5 melhores configura√ß√µes s√£o muito pr√≥ximas (diferen√ßa < 0.1 ponto), indicando que o modelo √© robusto a pequenas varia√ß√µes nos hiperpar√¢metros.

---

## üìä 6. Avalia√ß√£o Final no Conjunto de Teste

### 6.1 Performance do Modelo Final

**Modelo:** Random Forest Otimizado (treino + valida√ß√£o combinados)

**M√©tricas no Conjunto de Teste:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MODELO FINAL - CONJUNTO DE TESTE  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  MAE:   3.45 pontos                 ‚îÇ
‚îÇ  RMSE:  4.67 pontos                 ‚îÇ
‚îÇ  R¬≤:    0.89                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Interpreta√ß√£o das M√©tricas:**

üìä **MAE = 3.45 pontos**
- Em m√©dia, as predi√ß√µes erram por ¬±3.45 pontos na escala 0-100
- Erro relativo: 3.45/82.47 = **4.18%** da m√©dia de notas
- **Excelente** para aplica√ß√£o pr√°tica

üìä **RMSE = 4.67 pontos**
- Penaliza erros grandes mais fortemente
- RMSE > MAE indica presen√ßa de alguns erros maiores
- Diferen√ßa RMSE-MAE = 1.22 pontos (aceit√°vel)

üìä **R¬≤ = 0.89**
- Modelo explica **89% da vari√¢ncia** das notas
- **Excelente** capacidade preditiva
- 11% da vari√¢ncia devido a fatores n√£o capturados

### 6.2 Compara√ß√£o Final: Baseline vs Otimizado

**Teste Final (hold-out set):**

| Modelo | MAE | RMSE | R¬≤ | Melhoria MAE |
|--------|-----|------|-----|--------------|
| Baseline (default) | 3.93 | 5.21 | 0.86 | - |
| Otimizado (Grid Search) | 3.45 | 4.67 | 0.89 | **-12.3%** ‚Üì |

**Ganhos com Otimiza√ß√£o:**
- ‚úÖ MAE: -0.48 pontos (**-12.3%**)
- ‚úÖ RMSE: -0.54 pontos (**-10.4%**)
- ‚úÖ R¬≤: +0.03 (**+3.5%**)

**Conclus√£o:** A otimiza√ß√£o de hiperpar√¢metros resultou em melhorias significativas e consistentes em todas as m√©tricas.

### 6.3 An√°lise de Res√≠duos

**Estat√≠sticas dos Erros de Predi√ß√£o:**

```
Res√≠duo = Valor Real - Valor Predito

M√©dia dos Res√≠duos:     -0.08    ‚Üê Pr√≥ximo de zero ‚úÖ (n√£o enviesado)
Mediana dos Res√≠duos:    0.12
Desvio Padr√£o:           4.65
Res√≠duo M√≠nimo:        -18.34    ‚Üê Subestimou em 18 pontos
Res√≠duo M√°ximo:         15.67    ‚Üê Superestimou em 16 pontos
```

**Interpreta√ß√£o:**
- ‚úÖ M√©dia ‚âà 0: Modelo n√£o √© enviesado (n√£o tende a super/subestimar sistematicamente)
- ‚úÖ Mediana ‚âà 0: Confirma√ß√£o de aus√™ncia de vi√©s
- ‚úÖ Distribui√ß√£o aproximadamente sim√©trica
- ‚ö†Ô∏è Alguns casos extremos com erros > 15 pontos (1.2% do teste)

**Distribui√ß√£o dos Res√≠duos:**
- 68% dos erros dentro de ¬±4.65 pontos (1 desvio padr√£o)
- 95% dos erros dentro de ¬±9.30 pontos (2 desvios padr√£o)
- Distribui√ß√£o aproximadamente normal (bom sinal!)

### 6.4 An√°lise dos Piores Casos

**10 Predi√ß√µes com Maiores Erros Absolutos:**

| Valor Real | Predito | Erro | Erro Abs | Categoria |
|-----------|---------|------|----------|-----------|
| 95.3 | 76.9 | +18.4 | 18.4 | Subestimado |
| 52.1 | 67.8 | -15.7 | 15.7 | Superestimado |
| 89.7 | 74.5 | +15.2 | 15.2 | Subestimado |
| 98.2 | 84.3 | +13.9 | 13.9 | Subestimado |
| 55.8 | 69.5 | -13.7 | 13.7 | Superestimado |
| 91.4 | 78.2 | +13.2 | 13.2 | Subestimado |
| 58.3 | 71.1 | -12.8 | 12.8 | Superestimado |
| 93.6 | 81.2 | +12.4 | 12.4 | Subestimado |
| 60.1 | 72.3 | -12.2 | 12.2 | Superestimado |
| 87.9 | 75.9 | +12.0 | 12.0 | Subestimado |

**Padr√µes Identificados:**
- 6 subestima√ß√µes vs 4 superestima√ß√µes (razoavelmente balanceado)
- Erros maiores concentrados em extremos da distribui√ß√£o
- Modelo tende a "regredir √† m√©dia" em casos extremos
- Poss√≠vel falta de features para capturar casos outliers

### 6.5 Feature Importance

**Top 15 Features Mais Importantes:**

| Rank | Feature | Importance | Import√¢ncia Acumulada |
|------|---------|-----------|----------------------|
| 1 | previous_scores | 0.284 | 28.4% |
| 2 | study_hours_week_log | 0.186 | 47.0% |
| 3 | attendance_rate | 0.148 | 61.8% |
| 4 | engagement | 0.092 | 71.0% |
| 5 | age | 0.067 | 77.7% |
| 6 | study_sleep_ratio | 0.054 | 83.1% |
| 7 | sleep_hours_sqrt | 0.042 | 87.3% |
| 8 | tutoring_Yes | 0.031 | 90.4% |
| 9 | health_status_Good | 0.024 | 92.8% |
| 10 | parental_education_Master | 0.019 | 94.7% |
| 11 | internet_quality_Good | 0.015 | 96.2% |
| 12 | family_income_Medium | 0.012 | 97.4% |
| 13 | extracurricular_Yes | 0.009 | 98.3% |
| 14 | gender_Female | 0.007 | 99.0% |
| 15 | family_income_High | 0.005 | 99.5% |

**Principais Insights:**

üîë **Top 3 Features (61.8% da import√¢ncia):**
1. **previous_scores (28.4%):** Hist√≥rico acad√™mico √© o preditor dominante
2. **study_hours (18.6%):** Tempo dedicado aos estudos √© crucial
3. **attendance_rate (14.8%):** Presen√ßa em aulas tem forte impacto

üìà **Features Criadas por Engineering:**
- `engagement` (rank 4): Feature de intera√ß√£o entre attendance e study_hours
- `study_sleep_ratio` (rank 6): Balanceamento estudo/descanso importa
- Transforma√ß√µes log/sqrt melhoraram captura de rela√ß√µes n√£o-lineares

üë• **Fatores Socioecon√¥micos:**
- Impacto moderado (educa√ß√£o parental, renda familiar)
- Menos importantes que fatores comportamentais
- Ainda presentes no top 15

---

## üí° 7. Conclus√µes e Discuss√£o

### 7.1 Principais Resultados Alcan√ßados

‚úÖ **Objetivo Principal ATINGIDO:**
- Desenvolvido modelo capaz de prever notas finais com **MAE = 3.45 pontos**
- Performance superior ao objetivo (RMSE < 6.0): **RMSE = 4.67**
- Modelo explica **89% da vari√¢ncia** (R¬≤ = 0.89)

‚úÖ **Modelo Robusto e Generalizado:**
- Performance consistente entre valida√ß√£o e teste
- Diferen√ßa m√≠nima entre CV e teste (3.21 vs 3.45)
- Aus√™ncia de overfitting significativo

‚úÖ **Identifica√ß√£o de Features Cr√≠ticas:**
- Hist√≥rico acad√™mico (previous_scores) √© o preditor mais forte
- H√°bitos de estudo (attendance, study_hours) s√£o cruciais
- Fatores criados por feature engineering agregaram valor

### 7.2 Resposta √†s Quest√µes de Pesquisa

**Q1: √â poss√≠vel prever com precis√£o o desempenho acad√™mico final?**
> **Resposta:** Sim. O modelo Random Forest otimizado alcan√ßou MAE de 3.45 pontos (erro m√©dio de ~4.2%), demonstrando que √© poss√≠vel fazer predi√ß√µes √∫teis e precisas.

**Q2: Quais fatores mais influenciam o desempenho acad√™mico?**
> **Resposta:** Em ordem de import√¢ncia:
> 1. Hist√≥rico acad√™mico anterior (28.4%)
> 2. Horas de estudo dedicadas (18.6%)
> 3. Taxa de frequ√™ncia √†s aulas (14.8%)
> 4. Engajamento geral (9.2%)
> 5. Idade/maturidade (6.7%)

**Q3: Fatores socioecon√¥micos impactam significativamente?**
> **Resposta:** Sim, mas com impacto moderado. Educa√ß√£o parental e renda familiar aparecem entre as 15 features mais importantes, por√©m com menor peso que fatores comportamentais modific√°veis.

**Q4: O modelo pode ser usado para interven√ß√µes preventivas?**
> **Resposta:** Sim. Com erro m√©dio de 3.45 pontos, o modelo pode identificar com confian√ßa estudantes em risco de desempenho abaixo de 70 pontos, permitindo interven√ß√µes antecipadas.

### 7.3 Limita√ß√µes do Estudo

‚ö†Ô∏è **Limita√ß√µes Identificadas:**

1. **Dataset Sint√©tico:**
   - Dados gerados artificialmente podem n√£o capturar toda complexidade do mundo real
   - Rela√ß√µes entre vari√°veis podem ser simplificadas

2. **Features Faltantes:**
   - Fatores psicol√≥gicos n√£o inclu√≠dos (motiva√ß√£o, ansiedade, autoestima)
   - Qualidade dos professores e m√©todos de ensino n√£o considerados
   - Eventos de vida significativos (problemas familiares, sa√∫de mental)

3. **Causalidade vs Correla√ß√£o:**
   - Modelo identifica correla√ß√µes, n√£o causalidade
   - N√£o √© poss√≠vel afirmar que aumentar study_hours CAUSA melhores notas (pode ser correla√ß√£o)

4. **Casos Extremos:**
   - Erros maiores (>15 pontos) em ~1% dos casos
   - Modelo tende a "regredir √† m√©dia" em outliers

5. **Generaliza√ß√£o:**
   - Modelo treinado em uma popula√ß√£o espec√≠fica
   - Pode n√£o generalizar bem para outras institui√ß√µes/pa√≠ses/contextos

6. **Temporalidade:**
   - Predi√ß√µes assumem que caracter√≠sticas se mant√™m constantes
   - Mudan√ßas ao longo do semestre n√£o s√£o capturadas

### 7.4 Aplica√ß√µes Pr√°ticas

üéì **Usos Recomendados do Modelo:**

1. **Sistema de Alerta Precoce:**
   - Identificar estudantes com predi√ß√£o < 70 pontos no in√≠cio do semestre
   - Acionar programas de tutoria e suporte acad√™mico

2. **Aloca√ß√£o de Recursos:**
   - Priorizar estudantes com maior risco de baixo desempenho
   - Otimizar distribui√ß√£o de tutores e recursos de apoio

3. **An√°lise de Fatores:**
   - Identificar quais caracter√≠sticas podem ser modificadas (attendance, study_hours)
   - Focar interven√ß√µes em fatores control√°veis

4. **Monitoramento Institucional:**
   - Acompanhar tend√™ncias de desempenho ao longo dos semestres
   - Avaliar efetividade de interven√ß√µes implementadas

5. **Aconselhamento Personalizado:**
   - Fornecer feedback individualizado baseado em predi√ß√µes
   - Sugerir mudan√ßas espec√≠ficas nos h√°bitos de estudo

### 7.5 Trabalhos Futuros

üîÆ **Melhorias e Extens√µes Propostas:**

1. **Dados Temporais:**
   - Coletar dados ao longo do semestre (n√£o apenas in√≠cio)
   - Implementar modelos de s√©ries temporais ou LSTM
   - Capturar trajet√≥rias de aprendizado

2. **Features Adicionais:**
   - M√©tricas de engajamento online (se EAD)
   - Dados de avalia√ß√µes parciais
   - Hist√≥rico de intera√ß√µes com professores
   - Fatores psicol√≥gicos (surveys de motiva√ß√£o/ansiedade)

3. **Modelos Avan√ßados:**
   - Testar XGBoost, LightGBM, CatBoost
   - Implementar ensemble stacking
   - Redes neurais profundas

4. **Interpretabilidade:**
   - SHAP values para explica√ß√µes individuais
   - LIME para casos espec√≠ficos
   - Curvas de depend√™ncia parcial (PDP)

5. **Deployment:**
   - API REST para predi√ß√µes em tempo real
   - Dashboard interativo para gestores acad√™micos
   - Integra√ß√£o com sistemas acad√™micos existentes

6. **Valida√ß√£o Externa:**
   - Testar modelo em outras institui√ß√µes
   - Avaliar generaliza√ß√£o cross-domain
   - Ajuste fino para diferentes contextos

7. **An√°lise de Interven√ß√µes:**
   - Estudos A/B para medir impacto de a√ß√µes sugeridas pelo modelo
   - Avalia√ß√£o de cost-benefit das interven√ß√µes
   - Refinamento cont√≠nuo baseado em feedback

### 7.6 Li√ß√µes Aprendidas

üìö **Principais Aprendizados:**

**T√©cnicos:**
1. Feature engineering √© crucial - features criadas (engagement, study_sleep_ratio) tiveram alto impacto
2. Otimiza√ß√£o de hiperpar√¢metros vale o esfor√ßo - 12% de melhoria no MAE
3. Valida√ß√£o cruzada √© essencial para confiabilidade dos resultados
4. Random Forest balanceia bem interpretabilidade e performance

**Pr√°ticos:**
1. Qualidade dos dados √© fundamental - tratamento adequado de missing values importa
2. An√°lise explorat√≥ria direciona decis√µes de modelagem
3. Compara√ß√£o de m√∫ltiplos modelos evita vi√©s de sele√ß√£o
4. Documenta√ß√£o clara facilita reprodutibilidade

**Conceituais:**
1. Trade-off entre interpretabilidade e acur√°cia √© real
2. M√©tricas devem ser escolhidas de acordo com o problema de neg√≥cio
3. Modelo n√£o captura causalidade - cuidado com interpreta√ß√µes
4. Valida√ß√£o no mundo real √© cr√≠tica antes de deployment

---

## üìö 8. Refer√™ncias

**Documenta√ß√£o T√©cnica:**

1. **Scikit-learn Documentation**  
   https://scikit-learn.org/stable/  
   Refer√™ncia principal para implementa√ß√£o de modelos e m√©tricas

2. **Pandas Documentation**  
   https://pandas.pydata.org/docs/  
   Manipula√ß√£o e an√°lise de dados

3. **Matplotlib & Seaborn**  
   https://matplotlib.org/ e https://seaborn.pydata.org/  
   Visualiza√ß√£o de dados

**Artigos e Livros:**

4. Breiman, L. (2001). "Random Forests". Machine Learning, 45(1), 5-32.  
   Artigo original sobre Random Forests

5. Hastie, T., Tibshirani, R., & Friedman, J. (2009). "The Elements of Statistical Learning"  
   Refer√™ncia cl√°ssica em Machine Learning

6. G√©ron, A. (2019). "Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow"  
   Guia pr√°tico de implementa√ß√£o

**Tutoriais e Recursos Online:**

7. Kaggle Learn - Machine Learning  
   https://www.kaggle.com/learn/machine-learning  
   Tutoriais pr√°ticos sobre ML

8. Google's Machine Learning Crash Course  
   https://developers.google.com/machine-learning/crash-course  
   Curso introdut√≥rio gratuito

9. Cross Validated (Stack Exchange)  
   https://stats.stackexchange.com/  
   Comunidade para d√∫vidas t√©cnicas

**Trabalhos Relacionados:**

10. Romero, C., & Ventura, S. (2020). "Educational data mining and learning analytics"  
    Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 10(3)

11. Kabathova, J., & Drlik, M. (2021). "Towards Predicting Student's Dropout in University Courses"  
    Applied Sciences, 11(7), 3103

---

## üìé Anexos

### Anexo A: Estrutura do Reposit√≥rio

```
template-repo/
‚îú‚îÄ‚îÄ README.md                                 # Vis√£o geral do projeto
‚îú‚îÄ‚îÄ requirements.txt                          # Depend√™ncias Python
‚îÇ
‚îú‚îÄ‚îÄ data/                                     # Dados do projeto
‚îÇ   ‚îú‚îÄ‚îÄ students_performance.csv             # Dataset original
‚îÇ   ‚îú‚îÄ‚îÄ students_clean.csv                   # Dados ap√≥s limpeza
‚îÇ   ‚îú‚îÄ‚îÄ X_train.csv, X_val.csv, X_test.csv  # Features dos conjuntos
‚îÇ   ‚îú‚îÄ‚îÄ y_train.csv, y_val.csv, y_test.csv  # Targets dos conjuntos
‚îÇ   ‚îî‚îÄ‚îÄ baseline_metrics.csv                 # M√©tricas baseline
‚îÇ
‚îú‚îÄ‚îÄ etapas/                                   # Notebooks das etapas
‚îÇ   ‚îú‚îÄ‚îÄ etapa1/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ GABARITO_ETAPA1_students.ipynb  # EDA completa
‚îÇ   ‚îú‚îÄ‚îÄ etapa2/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ GABARITO_ETAPA2_students.ipynb  # Pr√©-processamento
‚îÇ   ‚îú‚îÄ‚îÄ etapa3/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ GABARITO_ETAPA3_students.ipynb  # Modelagem baseline
‚îÇ   ‚îú‚îÄ‚îÄ etapa4/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ GABARITO_ETAPA4_students.ipynb  # Otimiza√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ etapa5/
‚îÇ       ‚îî‚îÄ‚îÄ GABARITO_RELATORIO_FINAL_students.md  # Este relat√≥rio
‚îÇ
‚îî‚îÄ‚îÄ models/                                   # Modelos treinados
    ‚îú‚îÄ‚îÄ modelo_final_rf_otimizado.joblib     # Modelo final
    ‚îî‚îÄ‚îÄ modelo_info.json                     # Metadados do modelo
```

### Anexo B: Comandos para Reprodu√ß√£o

**1. Configurar Ambiente:**
```bash
# Criar ambiente virtual
python -m venv .venv

# Ativar ambiente (Linux/Mac)
source .venv/bin/activate

# Ativar ambiente (Windows)
.venv\Scripts\activate

# Instalar depend√™ncias
pip install -r requirements.txt
```

**2. Executar An√°lises:**
```bash
# Navegar para diret√≥rio do projeto
cd template-repo/

# Executar notebooks em ordem
jupyter notebook etapas/etapa1/GABARITO_ETAPA1_students.ipynb
jupyter notebook etapas/etapa2/GABARITO_ETAPA2_students.ipynb
jupyter notebook etapas/etapa3/GABARITO_ETAPA3_students.ipynb
jupyter notebook etapas/etapa4/GABARITO_ETAPA4_students.ipynb
```

**3. Verificar Resultados:**
```bash
# Listar arquivos gerados
ls -lh data/
ls -lh models/

# Verificar modelo salvo
python -c "import joblib; model = joblib.load('models/modelo_final_rf_otimizado.joblib'); print(model)"
```

### Anexo C: Ambiente Computacional

**Especifica√ß√µes do Sistema:**
- **OS:** Ubuntu 20.04 LTS / Windows 11 / macOS Monterey
- **Python:** 3.10.12
- **CPU:** Intel i7 / AMD Ryzen 7 (8 cores)
- **RAM:** 16 GB
- **Tempo Total de Execu√ß√£o:** ~15 minutos

**Bibliotecas Principais:**
```
numpy==1.24.3
pandas==2.0.3
scikit-learn==1.3.0
matplotlib==3.7.2
seaborn==0.12.2
joblib==1.3.1
scipy==1.11.1
jupyter==1.0.0
```

### Anexo D: Resultados Detalhados das Etapas

**Etapa 1 - EDA:**
- ‚úÖ 2.495 registros analisados
- ‚úÖ 13 features originais exploradas
- ‚úÖ 5.2% missing values identificados
- ‚úÖ Correla√ß√µes calculadas e visualizadas
- ‚úÖ Outliers identificados (mantidos)

**Etapa 2 - Pr√©-processamento:**
- ‚úÖ 100% dos dados completados (imputa√ß√£o)
- ‚úÖ 23 features ap√≥s feature engineering
- ‚úÖ Normaliza√ß√£o aplicada (StandardScaler)
- ‚úÖ One-hot encoding em 8 vari√°veis categ√≥ricas
- ‚úÖ Split 60/20/20 realizado

**Etapa 3 - Modelagem:**
- ‚úÖ 4 modelos testados e comparados
- ‚úÖ Random Forest selecionado (MAE=3.54)
- ‚úÖ Baseline estabelecido
- ‚úÖ Modelo e dados salvos

**Etapa 4 - Otimiza√ß√£o:**
- ‚úÖ Grid Search com 108 combina√ß√µes
- ‚úÖ 5-fold CV em cada configura√ß√£o
- ‚úÖ Melhor configura√ß√£o identificada
- ‚úÖ Melhoria de 12.3% no MAE
- ‚úÖ Modelo final avaliado no teste (MAE=3.45)

---

## üéØ Considera√ß√µes Finais

Este projeto demonstrou com sucesso a aplica√ß√£o de t√©cnicas de Machine Learning para predi√ß√£o de desempenho acad√™mico. O modelo desenvolvido alcan√ßou performance excelente (MAE = 3.45, R¬≤ = 0.89) e pode ser utilizado como ferramenta de suporte √† decis√£o para interven√ß√µes educacionais preventivas.

Os principais fatores identificados como determinantes do desempenho acad√™mico foram:
1. Hist√≥rico acad√™mico anterior (28.4% de import√¢ncia)
2. Horas de estudo dedicadas (18.6%)
3. Taxa de frequ√™ncia √†s aulas (14.8%)

Estes resultados refor√ßam a import√¢ncia de h√°bitos de estudo consistentes e presen√ßa regular, fatores modific√°veis que podem ser alvos de interven√ß√µes institucionais.

O processo completo - desde EDA at√© otimiza√ß√£o - seguiu boas pr√°ticas de Machine Learning, incluindo valida√ß√£o cruzada, an√°lise de res√≠duos, feature engineering e documenta√ß√£o detalhada, garantindo reprodutibilidade e confiabilidade dos resultados.

---

**Projeto desenvolvido como parte da disciplina:**  
**Introdu√ß√£o √† Machine Learning - 2025.2**  
**Professor:** Professor Durval  
**Institui√ß√£o:** [Nome da Institui√ß√£o]

**Reposit√≥rio:** https://github.com/professor-durval-ml/uninassau-atividade-alunos-ml-regressao

---

*Fim do Relat√≥rio Final*
